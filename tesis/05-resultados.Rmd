# Resultados {#Resultados}

```{r}
# Carga del modelo svar-sv
fit <- readRDS(here::here("Datos", "Finales", "modelo.rds"))

# Función para generar los gráficos de parámetros y varianzas
matplot2 <- function(...) matplot(..., type = "l", lty = 1, lwd = 2, bty = "n", ylab = "")
stat.helper <- function(z) c(mean(z), quantile(z, c(0.16, 0.84)))[c(2, 1, 3)]
gp <- seq(1985, 2020, 5) # marks for vertical lines
# colors, taken from http://www.cookbook-r.com
cols <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cols1 <- cols[c(2, 4, 2)]
make_plot <- function(.fit = fit, .type = "vcv", .var = 1, .title = "") {
    gp <- seq(1990, 2020, 5) # marks for vertical lines
    if(.type == "vcv") {
        # SD of unemployment residual
        # Get posterior draws
        sd_inf <- parameter.draws(.fit, type = .type, row = .var, col = .var)
        x1     <- t(apply(sqrt(sd_inf), 2, stat.helper))    
    } else if (grepl(x = .type, pattern = "lag")) {
        beta <- parameter.draws(fit, type = .type, row = .var, col = .var)
        x1   <- t(apply(beta, 2, stat.helper))    
    } else {
        beta_0 <- parameter.draws(fit, type = .type, row = .var, col = .var)
        x1     <- t(apply(beta_0, 2, stat.helper))       
    }
    xax <- seq(1990, 2018, length.out = NROW(x1)) # x axis
    # Plot
    if(.type == "vcv") {
        var <- sd.residuals.ols[.var]
    } else {
        var <- NULL
    }
    matplot2(x = xax, y = x1, ylim = c(min(x1), max(x1)), col = cols1, main = .title , xlab = "Fecha")
    abline(h = seq(min(x1), max(x1), length.out = 10), v = gp, lty = 4, lwd = 0.3)
    if(.type == "vcv") {
        abline(h = var, col = cols[1], lwd = 1.4, lty = 5)
    }
}

# Función para generar los IRF
plot_irf <- function(.fit = fit, impulse, response, scenario = 2) {
    ira <- impulse.responses(fit, impulse.variable = impulse, response.variable = response, scenario = scenario)
    # OLS impulse responses for comparison
    ira.ols <- irf(fit.ols, n.ahead = 20)[[impulse]][[response]][-1, 1]
    # Add to plot
    lines(x = 1:20, y = ira.ols, lwd = 1, lty = 5, col = "red")
}

# carga del modelo var
library(vars)
fit.ols <- readRDS(here::here("Datos", "Finales", "modelo-var-comun.rds"))
sd.residuals.ols <- apply(residuals(fit.ols), 2, sd)
```

Este capítulo presenta los resultados principales del trabajo. Primero se grafica la curva de Beveridge entre 1981 y 2018, se hace una partición por décadas para visualizar potenciales etapas. Realizamos una exploración de la relación entre vacantes laborales y el IVF del PIB y tasa de desempleo con producto.

Posteriormente analizamos las series utilizados y sus propiedades estadísticas, tales como raíces unitarias, raíces estacionales y cointegración utilizando distintos test estadísticos.

Realizamos una búsqueda de quiebres estructurales mediante distintos tipos de test estadísticos, como procesos de fluctuación, test F y dating.

Finalmente estimamos un TVP-VAR con volatilidad estocástica, donde analizamos la evolución de los rezagos de las variables endógenas y los desvíos estándar de la matriz de varianzas y covarianzas. Finalmente computamos las FIR por parte del producto sobre vacantes y desempleo.

## Curva de Beveridge

```{r beveridge-curve, fig.cap="Curva de Beveridge 1981-2018", fig.asp=1, fig.ncol = 2}
#out.width='.49\\linewidth'
# fig.fullwidth = TRUE
# fig.subcap=c('Curva de Beveridge trimestral', 'Curva de Beveridge anual')
notas = "Curva de Beveridge 1981-2018 para el departamento de Montevideo. La tasa de desempleo es calculada por el INE y el índice de vacantes es elaboración propia. Los colores celeste, violeta, rojo y verde representan respectivamente las décadas de 1980, 1990, 2000 y 2010. Se observa una curva con pendiente negativa y traslados paralelos entre 1980 y 2000. El periodo de 1990 muestra una transición hacia un punto más alejado del origen. El periodo de 2010 muestra un traslado hacia el origen."
fuentes = "Datos de "

plot_grid_split <- function(..., align = "hv", axis= "tblr"){
  aligned_plots <- cowplot::align_plots(..., align=align, axis=axis)
  plots <- lapply(1:length(aligned_plots), function(x){
    cowplot::ggdraw(aligned_plots[[x]])
  })
  invisible(capture.output(plots))
}
y_lim <- c(min(dt$ind_vac), max(dt$ind_vac)+1)
x_lim <- c(min(dt$td), max(dt$td)+1)
p1 <- ggplot(dt, aes(y = ind_vac, x = td, color = decada)) + 
    geom_point() +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10), limits = y_lim) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 10), limits = x_lim) +
    geom_path() +
    labs(x = "Tasa de desempleo", y = "Índice de vacantes", title = "Panel A. Datos trimestrales") +
    theme_Publication()

p3 <- dt[, .(td = mean(td), ind_vac = mean(ind_vac), pib = mean(pib), decada = min(decada)), keyby = .(ano)] %>%
    ggplot(., aes(y = ind_vac, x = td, color = decada, label = ano)) + 
    geom_point() +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10), limits = y_lim) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 10), limits = x_lim) +
    geom_path() +
    # position=position_jitter(width=.2,height=.02)
    geom_text(fontface = "bold", size = 2, position=position_jitter(width=.1,height=.02), color = "black") +
    labs(x = "Tasa de desempleo", y = "Índice de vacantes", title = "Panel B. Datos Anuales") +
    # geom_smooth(method = "lm", formula = y ~ x) +
    theme_Publication()
library(gridExtra)
library(grid)
# grid.arrange(p1,                             # First row with one plot spaning over 2 columns
#              arrangeGrob(p2, p3, ncol = 2), # Second row with 2 plots in 2 different columns
#              nrow = 2
#              )
# plot_grid_split(p1, p3)
library(patchwork)
# grid.arrange(p1, p3, nrow = 1)
(p1 + p3)
  
# lista = list(p1, p3)
# lista[[1]]
# cat('\n\n') 
# lista[[2]]
```

El primer hallazo del trabajo se observa en la Figura \@ref(fig:beveridge-curve) Panel A, con una relación negativa y convexa entre vacantes y desempleo en linea con la teoría económica para mercados laborales de economías de mercado. El color azul denota la década de 1980, violeta años 90, rojo los 2000 y finalmente verde 2010 a 2020. 

El segundo resultado, es que se existen claros movimientos a lo largo de la curva (por décadas) y traslados de la misma (entre décadas). 
En la Figura \@ref(fig:beveridge-curve) Panel B observamos los promedio anuales del índice de vacantes y tasa de desempleo, si analizamos por década, podemos identificar tres fases bien marcadas, años 80, 2000 y 2010. Donde los años 90 trasladan la curva hacia un nuevo estado con mayor desempleo ante igual cantidad de vacantes, el mismo se estabiliza en los 2000 y vuelve a cambiar de 2010 en adelante entrando en una nueva fase con menor desempleo ante misma cantidad de vacantes. Si nos limitamos a un lustro, podemos ver que a partir de 2005 parece haber un cambio en el mercado laboral, el cual se mantiene y vuelve a cambiar en 2010. Lo que se observa claramente en la curva, es que hay traslados paralelos en los últimos cuarenta años que podrían estar indicando un aumento y decenso de fricciones en el mercado de trabajo. Lo llamativo es que en la década de los ochenta y noventa bajo sistemáticamente la sindicalización, la negociación por rama en contraposición al aumento de la negociación por empresa, el estado dejo de participar en los consejos de salarios a partir de 1992 lo cual debería disminuir fricciones y generar movimientos hacia el origen, sin embargo, sucede lo contrario. Por otro lado, la importante cantidad de reformas aplicadas entre 2005 y 2015 que modificaron las reglas del juego de la economía y favorecieron sistemáticamente el poder de negociación de los trabajadores no parece que haya aumentado las fricciones, puesto que la CB se ha trasladado hacia el origen. Es decir, parece ser que estamos en un mercado laboral que soporta una tasa de desempleo mayor lo que podría indicar una mayor eficiencia del mismo, resultado a priori inesperado. El otro resultado relevante es que en los últimos diez años, ha habido un movimiento sobre la curva, disminuyendo la cantidad de vacantes y aumentando el desempleo, lo cual estaría indicando que la economía esta en la parte baja del ciclo económico.

```{r td-vac-pib, fig.cap="Producto-Vacantes y Producto-Desempleo (1981-2018)", fig.asp=1, fig.ncol = 2}
# , out.width='.49\\linewidth', fig.asp=1, fig.ncol = 2, fig.fullwidth = TRUE
notas = "Relación entre producto y vacantes, y,  producto y desempleo. Datos desde 1981 hasta 2018"
fuentes = "Datos de "
p1 <- dt[, .(td = mean(td), ind_vac = mean(ind_vac), pib = mean(pib), decada = min(decada)), keyby = .(ano)
   ] %>% 
ggplot(., aes(x = ind_vac, y = pib, color = decada, label = ano)) +
    geom_point() +
    geom_path() +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
    labs(x = "Índice de vacantes", y = "IVF PIB") +
    geom_text(size = 2, position=position_jitter(width=.02,height=.2), color = "black") +
    theme_Publication()

p2 <- dt[, .(td = mean(td), ind_vac = mean(ind_vac), pib = mean(pib), decada = min(decada)), keyby = .(ano)
   ] %>% 
    ggplot(., aes(x = td, y = pib, color = decada, label = ano)) +
    geom_point() +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
    geom_path() +
    labs(x = "Tasa de desempleo", y = "IVF PIB") +
    geom_text(size = 2, position=position_jitter(width=.02,height=.2), color = "black") +
    theme_Publication()
(p1 + p2)
# grid.arrange(p1, p2, ncol = 2)
# lista <- list(p1, p2)
# lista[[1]]
# cat('\n\n')
# lista[[2]]
```

En la Figura \@ref(fig:td-vac-pib)a podemos observar la relación entre vacantes y PIB. Es interesante notar la diferencia en la década de 2010, la notoria caída en las vacantes laborales no se ve acompañada por una caída del PBI, como puede observarse en los años 80 y 2000. La correlación entre PIB y vacantes se torna sistemáticamente negativa a partir del año 2012. La tasa de variación negativa en que caen las vacantes laborales entre 2011 y 2018, es prácticamente la misma entre 1998-2002 y  1981-1983, sin embargo el nivel de actividad no cae en ningún momento por lo que no se observa el movimiento de U típico de 80-82 y 98-2002. Esta observación en conjunto con el análisis de la CB podría estar indicando que el aumento del desempleo de los últimos años no se debe a mayores fricciones del mercado laboral, sino al desempleo estructural asociado a la diferencia sistemática entre las habilidades requeridas por el mercado y las ofrecidas por los trabajadores. Además debería haber un componente de cambio tecnológico e inversión en capital lo cual genere una menor demanda de trabajadores.

En la Figura \@ref(fig:td-vac-pib)b, observamos el mismo comportamiento de la CB en los años 90, una transición hacia lo que podríamos catalogar como un nuevo estado, una década de crecimiento con alto desempleo, hacia otra con crecimiento y caída del desempleo, los años 2000. Además, los 80 y 2000 vuelven a compartir la forma de U, solo que esta vez es en sentido contrario. La década de 2010, muestra a diferencia del gráfico anterior un comportamiento similar a los 90, se observa crecimiento económico con crecimiento del desempleo, aunque el nivel de actividad no cae en ningún momento. Nuevamente es llamativo que periodos con políticas laborales tan diferentes como los 90 y 2010 tengan un comportamiento similar en cuanto al crecimiento de la actividad y aumento del desempleo.

## Caracterización de las series


## Quiebres estructurales

Es de interés buscar la existencia de quiebres estructurales tanto en la tasa de vacantes como en la tasa de desempleo, en la medida que trabajamos bajo la hipótesis de que se han producido cambios relevantes en el mercado laboral que han alterado su funcionamiento. Hemos probado que la tasa de vacantes y desempleo son procesos integrados de orden uno, sin media incondicional\footnote{No es posible que sean procesos I(1) y tengan media incondicional, en la medida que esto generaría series con crecimiento permanente en el largo plazo.}. Queremos probar si modelando cada ecuación como un proceso autoregresivo, obtenemos quiebres estructurales.

En la Figura \@ref(fig:beveridge-curve)b gráficamos los datos de vacantes y desempleo junto a 4 modelos lineales, uno por cada década. La idea fue mostrar de forma intuitiva lo que parecen ser distintos periodos de la CB. Sin embargo, dicha agrupación no tiene sustento estadístico. A continuación, ponemos a prueba la hipótesis de existencia de algún quiebre estructural en la relación vacantes y desempleo y luego buscamos, en caso de existir, la fecha de dichos quiebres.

Planteamos:
\begin{equation}
log(ind\_vac_i) = \beta_i + \beta_i\log(td_i) + \epsilon_i
\end{equation}

Y testeamos:
\begin{align}
H_0: \beta_i &= \beta_0 \ \ \ (i = 1, ..., n) \\
H_1: \beta_i &\not= \beta_0 \ \ \ (i = 1, ..., n)
\end{align}


```{r quiebres, results='asis', fig.cap="Test de quiebes estructurales", fig.align='center'}
library(xtable)
# Data
dt_ts <- ts(data = dt[data.table::between(fecha, "1981-01-01", "2018-10-01"), 
                      .(pib, ind_vac, td)], 
            start = c(1981, 1), frequency = 4)
# Desestacionalizo con método x13 y conFiguración default
td      <- seasonal::final(seasonal::seas(dt_ts[, "td"]))
ind_vac <- seasonal::final(seasonal::seas(dt_ts[, "ind_vac"]))
pib     <- seasonal::final(seasonal::seas(dt_ts[, "pib"]))
# tasa de crecimiento del pib ~ log(diff(pib))
delta_pib <- diff(
            ts(log(dt[fecha >= "1980-04-01", pib]), start = c(1980, 2), frequency = 4),
            lag = 1, differences = 1
            )
delta_pib <- window(delta_pib, start = c(1981, 1), end = c(2018, 4))
pib <- window(pib, start = c(1981, 1), end = c(2018, 4))
dt_ts <- ts.union(pib, ind_vac, td, delta_pib)

# Modelo
reg <- log(ind_vac) ~ log(td) + 1
rt <- function(test, .data = dt_ts[, 2:3], .formula = reg, .h = 0.15, .dynamic = FALSE, pval = TRUE) {
    # Modelo
    mod1 <- strucchange::efp(formula = .formula, type = test, data = .data, h = .h, 
                             dynamic = .dynamic, vcov = sandwich::kernHAC)
    # Test
    if(pval) {
        round(sctest(mod1)$p.value[[1]],2)
    } else {
        round(sctest(mod1)$statistic[[1]],2)
    }
}
ft <- function(test = "supF", .formula = reg, .data = dt_ts[, 2:3], .from = .15, .to = NULL, pval = F) {
    mod <- strucchange::Fstats(formula = .formula, data = .data, from = .from, to = .to,
                               vcov = sandwich::kernHAC)
    if(pval) {
        round(sctest(mod, type = test)$p.value[[1]], 2)
    } else {
        round(sctest(mod, type = test)$statistic[[1]], 2)
    }
}
test = c("Rec-CUSUM", "OLS-CUSUM", "Score-CUSUM", "Rec-CUSUM(d)", "OLS-CUSUM(d)" ,"Score-CUSUM(d)", "Rec-MOSUM", 
         "OLS-MOSUM", "Score-MOSUM", "fluctuation", "ME", "expF", "aveF", "supF")
mat = matrix(data = NA, nrow = NROW(test), ncol = 4)
colnames(mat) <- c("Test", "est", "p-valor", "resultado")
mat <- as.data.frame(mat)
i = 0
for(t in test) {
    i = i + 1
    mat[i , 1] <- t
        for(bool in c(FALSE, TRUE)) {
            if(bool) {
                if(t %in% c("Rec-CUSUM(d)", "OLS-CUSUM(d)" ,"Score-CUSUM(d)")) {
                    mat[i, "p-valor"] <- rt(test = gsub(t, pattern = "\\(d\\)", replacement = ""), 
                                            pval = bool, .dynamic = T)
                } else if (t %in% c("expF", "aveF", "supF")) {
                    mat[i, "p-valor"] <- ft(test = t, pval = bool)
                } else {
                    mat[i, "p-valor"] <- rt(test = t, pval = bool, .dynamic = F)
                }
            } else {
                if(t %in% c("Rec-CUSUM(d)", "OLS-CUSUM(d)" ,"Score-CUSUM(d)")) {
                    mat[i, "est"] <- rt(test = gsub(t, pattern = "\\(d\\)", replacement = ""), 
                                        pval = bool, .dynamic = T)
                } else if (t %in% c("expF", "aveF", "supF")) {
                    mat[i, "est"] <- ft(test = t, pval = bool)
                } else {
                    mat[i, "est"] <- rt(test = t, pval = bool)
                }   
            }
        }
        if(mat[i, "p-valor"] > 0.1) {
        mat[i, "resultado"] <- ""
        } else if(mat[i, "p-valor"] >= 0.05 & mat[i, "p-valor"] < 0.1) {
            mat[i, "resultado"] <- "."
        }else if (mat[i, "p-valor"] >= 0.01 & mat[i, "p-valor"] < 0.05) {
            mat[i, "resultado"] <- "*"
        } else if (mat[i, "p-valor"] >= 0.001 & mat[i, "p-valor"] < 0.01) {
            mat[i, "resultado"] <- "**"
        } else {
            mat[i, "resultado"] <- "***"
        }
    mat[, 2:3] <- sapply(mat[,2:3], as.numeric)
}
colnames(mat) <- c("Test", "Estadístico", "p-valor", "Significación")
# comentario = list(pos = list(0), command = NULL)
# comentario$pos[[1]] = 1:11
texto = "Test de quiebres estructurales basados en residuos y estimadores. La columna Test presenta los test realizados, la columna Estadístico el valor de los estadísticos, la columna p-valor refiere a dicho valor para cada prueba. Significación refiere a los niveles de significación, . quiere decir no significativo al 5% pero si al 10%. Un * es estadísticamente significativo al 5%, ** es significativo al 1% mientras *** es significativo al 0.1%."
# comentario$command = c(paste("\\hline", 
#                            "\\footnotesize{",
#                            texto,"}\n", sep = ""))
# print.xtable(xtable::xtable(mat[1:11,], caption = "Test de quiebes estructurales"), type = "latex", timestamp = F,
#             add.to.row = comentario,
#             hline.after = c(-1,0))
kableExtra::kable(mat[1:11,], digits = 2, row.names = FALSE, align = "c", caption = "Test de quiebres estructurales", escape = F, booktabs = TRUE, format = "latex", longtable = F) %>% 
  kableExtra::kable_styling(full_width = F, latex_options = "hold_position") %>% 
  kableExtra::column_spec(column = 2:4, width = "2.5cm") %>%
  kableExtra::column_spec(column = 1, width = "5cm") %>%
  kableExtra::footnote(general = texto, general_title = "Notas:", 
                       threeparttable = TRUE)
```

En la columna Test, se identifican los test de quiebres estructural llevados a cabo siguiendo la nomenclatura usada por @Zeileis2002. La diferencia entre Rec-CUSUM y Rec-CUSUM(d) es que se permite la existencia de un rezago, ya que, @Society1988 muestran que los test CUSUM no pierden sus propiedades al relajar algunos supuestos, como trabajar con modelos dinámicos. En todos los casos que no se utilizan rezagos de la tasa de vacantes, se rechaza la hipótesis nula de invariabilidad en los parámetros, por tanto, no se rechaza la existencia de algún quiebre estructural en la relación entre vacantes y tasa de desempleo. Los únicos test que no rechazan H0 son Score-CUSUM y OLS-CUSUM(d) modelos que incluyen un parámetro autoregresivo de vacantes. En todos los casos, siguiendo a @Zeileis2004 se estimo la matriz de varianzas y covarianzas robusta ante la heteroscedasticidad y autocorrelación usando un estimador de kernel cuadrático HAC @Andrews1991 con un filtrado VAR(1) y una elección automática del ancho de banda basado en una aproximación AR(1)\footnote{El kernel génerico es $\omega_l = K(\frac{l}{B})$ con K la función de kernel y B el ancho de banda. Especificamente el kernel espectral tiene la siguiente forma $\omega_l = \frac{3}{z^2}(\frac{\sin(z)}{z} - \cos(z))$ siendo $l$ el rezago y $z = \frac{6\pi}{5}\frac{l}{B}$, ver @Andrews1991}.

En las Figuras XXX en el apéndice podemos observar las fluctuaciones del proceso empírico y su comparación con la fluctuación del proceso límite. Esto nos da una idea de en que periodo debería estar el o los quiebres en los parámetros, básicamente todos los test utilizados en la tabla XXX comparten que la hipótesis nula de la no existencia de cambio estructural debería ser rechazada cuando el proceso empírico  se vuelve improbablemente superior a las fluctuaciones del proceso límite @Zeileis2002. 
<!-- DESCRIBIR! -->

Adicionalmente los test Score, permiten observar variabilidad en la varianza, al sobrepasar el umbral esta es estadísticamente signifiticativa al 5\%. Tanto en el test Score-CUSUM como Score-MOSUM la varianza muestra fluctuaciones entre 1990 y 1995, y en torno a 2010-2011, sobrepasando el umbral. Por otra parte, el test Score-CUSUM con rezagos con p-valor 0.5, muestra una varianza al límite del umbral, pero sin sobrepasarlo. Esto da indicio de que es posible plantear un modelo que no solo tome en cuenta los quiebres en los parámetros sino también en la varianza de los errores lo cual puede mejorar la estímación de los quiebres @BaiPerron2003, por ello se estiman modelos de quiebres tanto de parámetros como varianza siguiendo a @Zeileis2010.

```{r ftest, fig.cap="Estadísticos F", results='asis'}
texto = "Test de estadísticos F. expF refiere al test exponencial ver XXX. El test aveF refiere al xxxx. El test supF refiere a xxxx. La columna estadístico muestra el valor del estadístico, p-valor los p-valores correspondientes en cada prueba. Significación refiere a los niveles de significación, . quiere decir no significativo al 5% pero si al 10%. Un * es estadísticamente significativo al 5%, ** es significativo al 1% mientras *** es significativo al 0.1%."
kableExtra::kable(mat[12:14,], digits = 2, row.names = FALSE, align = "c", caption = "Test de estadístico F", escape = F, booktabs = TRUE, format = "latex", longtable = F) %>% 
  kableExtra::kable_styling(full_width = F, latex_options = "hold_position") %>% 
  kableExtra::column_spec(column = 1:4, width = "3cm") %>%
  kableExtra::footnote(general = texto, general_title = "Notas:", 
                       threeparttable = TRUE)
```

Un segundo tipo de test, es el F, originalmente el test de @Chow1960. El cual define la hipótesis alternativa y require saber a priori en que momento cambian los parámetros. Sin embargo, es posible calcular el estadístico F para un rango de valores especificados, definiendo el tamaño mínimo del intervalo a considerar, en base a un parámetro de ancha de banda, h.

@Andrews1993 y @Andrews1994 sugieren 3 tipos de test F a considerar, supF, aveF y expF. En el Cuadro \ref{ftest} podemos observar el test, el valor del estadístico y el p-valor asociado. Se uso la misma matriz de variazas y covarianzas robusta que en el caso anterior. En los 3 casos, encontramos un quiebre estructural en torno a 1990-I, resultado en linea con @Urrestarazu1997.

```{r coefTestEstructural, fig.cap='Coeficientes de diferentes períodos', results="asis", fig.align='center'}
library(fxregime)
# FXREGIME 
reg <- log(ind_vac) ~ log(td) + 1
# Buscamos los quiebres cada 5 años
mod_reg <- fxregimes(formula = reg, data = zoo(dt_ts, frequency = 4), h = 20, 
                     breaks = 5)
# confint(mod_reg, level = 0.95, vcov = kernHAC)
# Resúmen completo, primero re-estimar el modelo en los subperiodos y luego aplicando summary
mod_rf <- refit(mod_reg)
# print(xtable(round(coef(mod_reg), 4)), comment = FALSE)
texto = "Explicación de los coeficientes del modelo"
kableExtra::kable(coef(mod_reg), digits = 2, row.names = T, align = "c", caption = "Coeficientes de cada periodo", escape = F, booktabs = TRUE, format = "latex", longtable = F, 
                  col.names = c("$\\beta_0$", "$\\beta_1$", "$\\sigma^2$")
                  ) %>% 
  kableExtra::kable_styling(full_width = F, latex_options = "hold_position") %>% 
  kableExtra::column_spec(column = 2:4, width = "2cm") %>%
  kableExtra::column_spec(column = 1, width = "5cm") %>%
  kableExtra::footnote(general = texto, general_title = "Notas:", 
                       threeparttable = TRUE)
```


```{r vcovHAC-andrews, fig.cap='Ponderadores Andrews', results='asis', fig.align='center'}
get_model <- function(.mod, .mat = sandwich::vcovHAC) {
    a = data.table::rbindlist(
        lapply(.mod, function(x) {
        broom::tidy(
            lmtest::coeftest(x, .mat)
            )
    }), 
    use.names = TRUE, idcol = "modelo")
    setnames(a, old = names(a), 
            new = c("Modelo", "coeficiente", "Estimación", "Estándar error", 
                    "Estadístico", "p-valor"))
    a[`p-valor` > 0.1, sigf := ""]
    a[between(`p-valor`, lower = 0.05, 0.1),   sigf := "."]
    a[between(`p-valor`, lower = 0.01, 0.05),  sigf := "*"]
    a[between(`p-valor`, lower = 0.001, 0.01), sigf := "**"]
    a[between(`p-valor`, lower = 0, 0.001),    sigf := "***"]
    a[coeficiente == "(Intercept)", coeficiente := "$\\hat{\\beta}_0$"]
    a[coeficiente == "log(td)", coeficiente := "$\\hat{\\beta}_1$"]
    a[coeficiente == "(Variance)", coeficiente := "$\\hat{\\sigma}^2$"]
    a
}

texto = "Explicación de los coeficientes del modelo"
kableExtra::kable(get_model(.mod = mod_rf, .mat = sandwich::vcovHAC), digits = 2, row.names = F, align = "c", caption = "Coeficientes de cada periodo", escape = F, booktabs = TRUE, format = "latex", longtable = F, 
                  col.names = c("Periodo", "Coeficiente", "Estimación", "Estándar error", "Estadístico", "p-valor", "Significación")
                  ) %>% 
  kableExtra::kable_styling(latex_options = "scale_down") %>% 
  kableExtra::footnote(general = texto, general_title = "Notas:", 
                       threeparttable = TRUE)
```

Finalmente, pasamos a calcular todos los posibles periodos de quiebres estructurales de forma generalizada. Para ello se siguen los trabajos de @BaiPerron2003, @BaiPerron1998 y aplicaciones de @Zeileis2003, en especial a @Zeileis2010. Obtenemos 3 quiebres estructurales en los años 1990-II, 1996-II y 2013-II usando como función objetivo la log-verosimilitud negativa\footnote{Los quiebres son exactamente iguales si las variables se modelan en niveles o logaritmos. Es posible modelar otro cambio estructural eligiendo otra función objetivo como el BIC o RSS, sin embargo dicho intervalo es extremadamente amplio al computarlo con una matriz HAC, al elegir un máximo de 3 puntos de quiebres se obtienen los mismos resultados, si se fija un máximo de 4 se obtiene un quiebre adicional en 2004-I}. Por lo tanto, los 4 periodos de análisis son 1981-I.1990-II, 1990-III.1996-II, 1996-III.2013-I y 2013-II.2018.IV. En la tabla \@ref(fig:vcovHAC-andrews) observamos que en todos los periodos los parámetros muestran el signo correcto según la teoría, negativo. En todos los casos son estadísticamente significativos al 5\%, usando una matriz HAC con ponderadores de Andrews. Sin embargo, usando ponderadores de Kernel en el segundo periodo el p-valor es 0.12. Dada la existencia de autocorrelación y heteroscedasticidad, la elección de la matriz de ponderadores es relevante y puede generar variaciones en la significatividad estadística de algunos parámetros. Por ello las tablas \@ref(fig:vcovHAC-lumley), \@ref(fig:kernHAC), \@ref(fig:kernHAC-parzen) y \@ref(fig:NeweyWest) muestran diferentes ponderaciones para los distintos periodos. Es de notar que el único momento que podría ser discutible es entre 1990-III.1996-II, en el cual dependiendo la elección de la matriz el parámetro de la tasa de desempleo puede resultar no significativo, sin embargo, si se estima un modelo lineal pero sin varianza de los errores ni intercepto, la tasa de desempleo es estadísticamente significativa, con el signo del coeficiente negativo. En el resto de los casos los coeficientes son estadísticamente significativos al nivel $\alpha = 0.05$, al igual que las varianzas de cada periodo.

```{r BCtest, fig.cap="Curva de Beveridge por periodo", fig.align="center"}
# Hacer una función, esto es muy manual.
dt[fecha <= "1990-04-01", decada_test := "1-periodo"
   ][between(fecha, "1990-07-01", "1996-04-01"), decada_test := "2-periodo"
     ][between(fecha, "1996-07-01", "2013-04-01"), decada_test := "3-periodo"
       ][between(fecha, "2013-07-01", "2019-10-01"), decada_test := "4-periodo"]
notas = "Curvas de Beveridge para cada periodo bbtenido mediante test de quiebre estructural"
fuentes = "Datos de elaboración propia"

ggplot(dt, aes(y = ind_vac, x = td, color = decada_test)) + 
    geom_point() +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
    labs(x = "Tasa de desempleo", y = "Índice de vacantes") +
    geom_smooth(method = "lm", formula = y ~ x) +
    theme_Publication()
# Agregar el caso de 4 quiebres y por tanto 5 particiones usando breakpoint.
```

La Figura \@ref(fig:BCtest) muestras las CB estimadas para cada periodo. En todos los casos se mantiene una relación negativa entre vacantes y desempleo. A la vez que se observan cambios de nivel y pendiente. El primer periodo desde 1981-I hasta 1990-II muestra una curva comparativamente más cercana al origen, que para 1990-III a 1996-II se aleja de forma paralela, lo mismo vuelve a suceder en 1996-III a 2013-II, denotando lo que podría ser un mercado laboral menos eficiente. El comportamiento se modifica a partir de 2013-III en donde la curva tiene un cambio paralelo y levamente de pendiente hacia el origen.
<!-- Profundizar esta explicación y cuales pueden ser las causas -->

## SVAR-SV

Por último, realizamos una estimación multivariada de un vector autoregresivo con parámetros variables y volatilidad estocástica siguiendo a @Primiceri2005, @Lubik2016 y @Lubik2016b, usando el algoritmo corregido por @Primiceri2015. Nos interesa analizar la variabilidad en los parámetros beta y en la matriz de varianzas y covarianzas, sumado al efecto de un shock por parte del producto sobre vacantes y desempleo\footnote{Es posible utilizar el test desarrollado por @Stock1998.}.

Usamos las primeras 36 observaciones, 9 años, desde 1981-I hasta 1989-IV para calibrar las distribuciones a priori, quedando un periodo efectivo desde 1990 hasta 2018. La restricción de identificación que se impone es que son los shocks desde el producto (shocks de productividad) los cuales afectan al desempleo y las vacantes laborales, con un rezago. Por lo tanto, el pib es la primer variable, seguido del índice de vacantes y la tasa de desempleo. El orden de la segunda y tercer variable, no es una restricción de identificación sino una normalización necesaria que puede modificar los resultados [@Primiceri2005], sin embargo, en este caso el orden no genera diferencias.

<!-- \newpage -->
<!-- ```{r svar-varianzas, fig.cap="Media posterior, cuantiles 16 y 84 de los desvíos estándar", fig.align="center", fig.height=8, fig.width=6} -->
<!-- # Análisis de la varianza de los parámetros -->
<!-- par(mfrow = c(3, 1)) -->
<!-- make_plot(.fit = fit, .type = "vcv", .var = 1, .title = "pib") -->
<!-- make_plot(.fit = fit, .type = "vcv", .var = 2, .title = "vacantes") -->
<!-- make_plot(.fit = fit, .type = "vcv", .var = 3, .title = "desempleo") -->
<!-- ``` -->
<!-- \newpage -->

En la Figura \@ref(fig:svar-parameters) observamos los desvíos estandar variables a lo largo del tiempo de los residuos del modelo, se gráfica la media (posterior) y los cuantiles 16 y 84\footnote{Normalidad}. El gráfico presenta dos interesantes características. La primera es que las vacantes laborales son estables para el periodo, por lo cual bien podria imponerse una restricción sobre la matriz de varianzas y covarianzas. El segundo y más interesante es que si bien la magnitud es leve, parecen existir dos periodos desde 1990 hasta 2005 y desde 2005 en adelante con una transición suave, donde el primero presenta una mayor varianza tanto para el pib como la tasa desempleo. En el caso de las vacantes, no se observan diferencias.



\begin{landscape}
```{r svar-parameters, fig.cap="Media posterior y volatilidades modelo TVP-VAR", fig.height=5, fig.width=8, fig.align="center"}
notas = "Se graficas las matrices $\\hat{A}_{jt}$ y $\\hat{\\Sigma}_{jt}$ desde 1990 hasta 2018 para el producto, índice de vacantes y tasa de desempleo. Observamos los desvíos estandar de los residuos del modelo, se gráfica la media (posterior) y los cuantiles 16 y 84. Si bien la magnitud es leve, parecen existir dos periodos desde 1990 hasta 2005 y desde 2005 en adelante con una transición suave, donde el primero presenta una mayor varianza tanto para el pib como la tasa desempleo. En el caso de las vacantes, no se observan diferencias."
fuentes = "Serie de producto facilitada por CINVE. Tasa de desempleo obtenida de INE. Índice de vacantes construcción propia."
par(mfrow = c(3, 3))
for(i in c("intercept", "lag1", "vcv")) {
    for(j in 1:3) {
      if(j == 1) k <- "pib" else if (j == 2) k <- "vacantes" else k <- "desempleo"
      if (i == "intercept") {
        k <- eval(bquote(expression(.(k) ~ A[0][t])))
      } else if (i == "lag1") {
        k <- eval(bquote(expression(.(k) ~ A[1][t])))
      } else {
        k <- eval(bquote(expression(.(k) ~ Sigma[j][t])))
      }
      make_plot(.fit = fit, .type = i, .var = j, .title = k)
    }
}
```
\end{landscape}


También se identifica que los parámetros se mantienen invariantes a lo largo del periodo de análisis, se muestra la estimación de un TVP-VAR(1) en vez de un TVP-VAR(2), dado que los resultados no se modifican y se facilita su visualización.

El resultado es robusto frente a diferentes especificaciones, con variables en niveles o en logaritmos los resultados no cambian. Adicionalmente se estimo un modelo bivariado con desempleo y vacantes, tanto en niveles como en logaritmos, obteniendo los mismos resultados. Esto estaría indicando la posibilidad de trabajar con un modelo de parámetros fijos y con volatilidad estocástica.

```{r FIR, fig.cap="FIR", out.width='1\\linewidth'}
notas = "FIR"
# Tengo que modificar plot_irf para que sea en español y que los label de eje y estén rotados en 90 grados. O sino pasarlo a ggplot.
# Además tengo que agregar un súbtitlo (al menos a los que son 2 gráficos)
par(mfrow = c(1,2))
plot_irf(impulse = 1, response = 2)
plot_irf(impulse = 1, response = 3)
```

Por último analizamos el efecto de un shock en el producto, interpretado como un shock de productividad sobre vacantes y desempleo. En la Figura \@ref(fig:FIR)a tenemos el shocks desde el producto hacia las vacantes laborales el efecto es positivo en todo momento, esto tiene sentido en la medida que una innovación de productividad, debería generar que la demanda laboral de las empresas se vea aumentado, en la medida que crezca el nivel de producción de la economía. Al contrario en la Figura \@ref(fig:FIR)b observamos como el efecto del shock genera un efecto negativo en todo momento sobre la tasa de desemeplo, nuevamente esto es satisfactorio. Al mejorar la productividad de la economía, el desempleo debería disminuir en la medida que la economía es capaz de aumentar su producción, lo cual lleva a que las empresas aumenten su contratación (más o menos dependiendo de cuan sesgado sea hacia el uso de tecnología y capital). Los efectos de entrada o salida de personas a la PEA esta presente en ambos casos puesto que el índice de vacantes esta normalizado por la PEA, al igual que la tasa de desempleo.
<!-- MEJORAR LA EXPLICACIÓN Y ARGUMENTACIÓN -->
