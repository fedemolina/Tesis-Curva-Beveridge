---
title: "Curva de Beveridge"
subtitle: "Uruguay • 1980-2018"
author: ".large[Federico Molina | Defensa de tesis|] <br>Tutor: Rodrigo Ceni"
institute: FCEA, UDELAR
lang: "es-CO"
keywords: Curva de Beveridge, SVARSV, Quiebre estructural
date: 2020-06-26 <i class='fa fa-calendar' aria-hidden='true'></i> &ensp;<br> Slides disponibles en <http://bit.ly/infer-useR><br> Tesis disponible en <https://infer.netlify.com>
output: 
  xaringan::moon_reader:
    encoding: 'UTF-8'
    self_contained: false
    chakra: 'assets/remark-latest.min.js'
    css: 'assets/presentation.css'
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightLanguage: r
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      slideNumberFormat: "Curva de Beveridge en Uruguay 1980-2018, Federico Molina • %current%/%total% • "
      countdown: 90000
---
exclude: true
count: false

```{r,echo=FALSE,child="assets/header-presentation.Rmd"}
```

```{r paquetes, echo=FALSE, message=FALSE, warning=FALSE}
# load the packages you need
knitr::opts_chunk$set(echo = FALSE,
                      message=FALSE, 
                      warning=FALSE,
                      cache = TRUE,
                      fig.height = 6,
                      fig.width = 10)

library(ggplot2)
library(data.table)
library(magrittr)
library(patchwork)
library(grid)
library(ggthemes)
library(scales)
library(bvarsv)
```

```{r, load_refs, include=FALSE, cache=FALSE}
library(RefManageR)
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           # cite.style = "alphabetic",
           style = "markdown",
           hyperlink = FALSE,
           dashed = TRUE)
myBib <- ReadBib("./TesisBeveridgeCurve.bib", check = FALSE)
```

---
class: right, middle, presentation-slide, seccion-slide
count: false

<img src="assets/foto-perfil.png" width="150px"/>

# Encuentrame en...

<a href="https://twitter.com/FedeMolinaMagne"><i class="fa fa-twitter fa-fw"></i>&nbsp; @FedeMolinaMagne</a><br>
<a href="https://github.com/fedemolina"><i class="fa fa-github fa-fw"></i>&nbsp; @fedemolina</a><br>
<!-- <a href="https://juliasilge.com"><i class="fa fa-link fa-fw"></i>&nbsp; juliasilge.com</a><br> -->
<!-- <a href="https://tidytextmining.com"><i class="fa fa-book fa-fw"></i>&nbsp; tidytextmining.com</a><br> -->
<a href="mailto:federicoandresmolina@gmail.com"><i class="fa fa-paper-plane fa-fw"></i>&nbsp; federicoandresmolina@gmail.com</a><br> 
<a href="mailto:fmolina@iesta.edu.uy"><i class="fa fa-paper-plane fa-fw"></i>&nbsp; fmolina@iesta.edu.uy</a>

---
name: inicio
count: false
class: tabla-inicio-slide, presentation-slide, seccion-slide

# Presentación

## [Introducción](#intro-inicio)
## [Curva de Beveridge](#cb-inicio)
## [Fuentes de datos](#datos-inicio)
## [Estrategías Empíricas](#estrategias-inicio)
### [TVP-VAR-SV](#estrategias-svar)
### [Quiebres estructurales](#estrategias-quiebres0)
## [Resultados](#resultados-inicio)
## [Discusión](#discusion-inicio)
## [Conclusiones](#conclusiones)

---
name: intro-inicio
class: presentation-slide, seccion-slide, center, middle
count: false

# .largest[[INTRODUCCIÓN](#inicio)]

---
name: intro-template
class: top, left

###### [Introducción](#inicio)

---
template: intro-template
class: middle, center
.largest[¿Qué es la Curva de Beveridge?]

---
background-image: url(assets/CB.svg)
background-size: contain
class: right, center

--

.center.largest.middle[¿Por qué estudiarla?]

--

<body>
  <p class = "content">
   <strong>
.large[Vacantes laborales son un proxy de la demanda laboral, interesa saber el comportamiento de firmas]
 </strong>
</p>
</body>
--

<body>
  <p class = "content">
   <strong> 
.large[Relevancia teórica, al ser un marco de análisis teórico de la dinámica del mercado laboral]
  </strong>
</p>
</body>

--

<body>
  <p class = "content">
   <strong>
.large[Relevancia práctica, descripción del mercado laboral en generación y cuantificación de políticas]
  </strong>
</p>
</body>

--

<body>
  <p class = "content">
   <strong>
.large[Resume información esencial sobre el funcionamiento del mercado de trabajo y shocks que lo afectan (institucionales, tecnológicos, productividad, ciclo)]
  </strong>
</p>
</body>

--

<body>
  <p class = "content">
   <strong>
.large[Permite identificar en que parte del ciclo esta la economía]
  </strong>
</p>
</body>

--

<body>
  <p class = "content">
   <strong>
.large[Desplazamiento de la curva de Beveridge implica modificación el desempleo natural de una economía]
  </strong>
</p>
</body>



???
Relevancia teórico, relevancia práctica en la descripción del mercado laboral, en la generación y cuantificación de políticas.
Blanchard & Diamond:
Análisis teórico de la dinámica agregada del mercado laboral ha estado organizado en base a dos relaciones, la curva de Phillips y la curva de Beveridge.
Resume información esencial sobre el funcionamiento del mercado de trabajo y shocks que afecten al mismo.

Definición de vacante y desocupados:
Las vacantes se entienden como aquella posición dentro de la firma que el empleador busca cubrir activamente durante un periodo de referencia.
Los desocupados se definen como aquellas personas que durante un periodo de tiempo buscan trabajo remunerado activamente pero no logran obtenerlo.

---
template: intro-template

* .large[Motivación]
  + Ausencia de datos de vacantes públicos, prolongados y sistematizados, por ende Uruguay no tiene una Curva de Beveridge. Existencia de datos web disponibles que posibilitan cruzamiento de fuentes mediante análisis de texto.
  + Trabajo anterior data de 25 años atrás. 
      + Nuevos datos y fuentes disponibles
      + Nuevas técnicas estadísticas 
  + Cambios relevantes en el mercado laboral en los últimos 40 años:
      + Década de 1980
      + Década de 1990
      + Década de 2000
      + Decada de 2010
      + Cambios/shocks institucionales, de ciclo económico, demográficos y tecnológicos.
      
* Investigación reproducible, herramientas open source, código abierto, datos públicos.

<!-- ???  -->
<!-- 1980: Retorno de la democracia, aumento de sindicalización, retorno de consejos de salarios, crisis de la tablita. -->
<!-- 1990: Cae la sindicalización, disminuye la negociación por rama de actividad, no se convocan consejos de salarios. -->
<!-- 2000: Crisis económica, múltiples reformas estructurales y cambios en las reglas del juego: Retornan los consejos de salarios, se fomenta la negociación por rama de actividad, protección de trabajadores en procesos de terciarización, aumento sostenido del salario mínimo, se limita la jornada de trabajadores rurales, regulación del trabajo de servicio doméstico, se aprueba la ley de responsabilidad penal empresarial. -->
<!-- 2010: Cambios tecnológicos relevantes en la búsqueda y contratación laboral. Aumento del uso de internet, ingreso de nuevos actores en la prensa laboral, creación de portales laborales, centralización de solicitudes de empleos públicos (Uruguay Concursa). -->

---
template: intro-template

* .large[Pregunta de investigación]
  + ¿La Curva de Beveridge presenta cambios de pendiente y/o traslados paralelos en Uruguay entre 1980 y 2018?
  
--
  
* .large[Hipótesis]
  + Relación de vacantes y desempleo no debería ser estable para el periodo analizado dada la gran cantidad de cambios estructurales.
  + Ho) La relación es estable
  + H1) La relación no es estable

--

* .large[Objetivos]
  + Principal
      + Probar la no existencia de estabilidad parámetrica
  + Específico
      + Crear un indicador de vacantes laborales público, reproducible y sistemático.
      + Verificar relación negativa vacantes-desempleo
      + Verificar resultados previos para Uruguay.
      
---
name: cb-inicio
class: center, middle
background-image: url(assets/CB.svg)
background-size: contain
count: false

# .largest[[CURVA DE BEVERIDGE](#inicio)]

---
name: datos-1
class: no-logo-slide

###### [Antecedentes](#cb-inicio)

```{r include=FALSE}
autores <- c("Beveridge (1944)", 
             "Dicks-Mireaux (1958)",
             "Gujarati (1972)",
             "Bewley (1979)",
             "Evans (1977)",
             "Nickell, et al. (2002)",
             "Bouvet (2012)",
             "Hobijn y Şahing (2013)",
             "Abraham y Watcher (1987)",
             "Blanchard y Diamond (1989)",
             "Barnichon (2010)",
             "Daly, et al. (2012)",
             "Benati y Lubik (2013)",
             "Lubik (2013)",
             "Elsby, et al. (2015)",
             "Lubik, Matthes y Owens (2016)"
             )
temas <- c("Identifica relación negativa", "Examinan confiabilidad del indicador. Utilizan CB para medir exceso de demanda en M.trabajo", "Analiza el efecto del Redundancy Payment Act.", "Factores demoráficos (-) y variaciones en los flujos de destrucción de puestos laborales", "Desempleo total y registrado, variación entre regiones y en el tiempo",
           "Modificaciones en instituciones del M.laboral: Unión sindical y protecciones en empleo",
           "Rígideces en el mercado laboral, aumento de salarios mínimos y seguros de desempleo",
           "Modificación en la composición de vacantes disminuyendo eficiencia del matching, disminución tasa de abandono",
           "Índice, cambios a composición del empleo, dispersión de DA entre sectores, alteraciones comp. de búsqueda", 
           "VAR u,v,l. Shocks cíclicos (DA), sectoriales (realocación), shocks oferta. CP shocks OA", 
           "Índice de vacantes compuesto",
           "Estudio sobre tasa natural de desempleo",
           "TVP-VAR-SV variación en pendiente",
           "TVP-VAR-SV. Caída cíclica de la productividad y (-) eficiencia del matching",
           "Modificaciones en procesos de contratación", 
           "TVP-VAR-SV sin variación")
region <- c("Inglaterra", 
            "Inglaterra",
            "Inglaterra",
            "Inglaterra",
            "Inglaterra",
            "OCDE",
            "Europa",
            "OCDE",
            "EEUU",
            "EEUU",
            "EEUU",
            "EEUU",
            "EEUU",
            "EEUU",
            "OCDE",
            "EEUU"
)
periodo <- c("1910-1950",
             "1946-1956",
             "1958-1972", 
             "1958-1971",
             "1961-1971",
             "1960-1990",
             "1975-2004",
             "1960-2011",
             "1951-1985",
             "1952-1988",
             "1977-2010",
             "1951-2011",
             "1951-2012",
             "1950-2013",
             "1951-2013",
             "2000-2013"
             )
autores_al <- c(
             "García, et al. (2002)",
             "Albertini y rumpkin (2019)",
             "Rama (1988)",
             "Bucheli, et al. (1993)",
             "Urrestarazu (1997)",
             "Espino, et al. (2011)"
             )
region_al <- c(
            "Chile",
            "Argentina",
            "Uruguay",
            "Uruguay",
            "Uruguay",
            "Uruguay"
)
tabla <- data.table::data.table(
                    Region = region,
                    Autores = autores,
                    Tema = temas,
                    Periodo = periodo
                    )
```


```{r echo=FALSE}
DT::datatable(tabla, rownames = FALSE, options = list(dom = "t", pageLength = 16,
                initComplete = DT::JS(
    "function(settings, json) {",
    "$(this.api().table().header()).css({'background-color': '#000', 'color': '#fff'});",
    "}")))
```

---
name: datos-1-al
class: no-logo-slide

###### [Antecedentes](#cb-inicio)

```{r include=FALSE}
autores_al <- c(
             "García, et al. (2002)",
             "Albertini y rumpkin (2019)",
             "Rama (1988)",
             "Bucheli, et al. (1993)",
             "Urrestarazu (1997)",
             "Espino, et al. (2011)")
region_al <- c(
            "Chile",
            "Argentina",
            "Uruguay",
            "Uruguay",
            "Uruguay",
            "Uruguay")
temas_al <- c("Construcción índice", "Construcción índice", "Construcción índice", "Estimación CB", "Construcción índice, estimación CB", "Recolección de datos y comparación ECH")
periodo_al <- c("1986-2002", "2000-2018", "1978-1987", "1980-1993", "2000-2009")

tabla <- data.table::data.table(
                    Region = region_al,
                    Autores = autores_al,
                    Tema = temas_al,
                    periodo = periodo_al
                    )
```


```{r echo=FALSE}
DT::datatable(tabla, rownames = FALSE, options = list(dom = "t", pageLength = 6, 
                initComplete = DT::JS(
    "function(settings, json) {",
    "$(this.api().table().header()).css({'background-color': '#000', 'color': '#fff'});",
    "}")))
```

```{r, include = FALSE}
factores <- c("Institucionales", "Tecnológicos", "Ciclo")
autores_institucionales <- c("Gujarati (1972)", "Blanchard y Wolfers (2000)", "Nickell, et al. (2002", "Bouvet (2012)")
autores_tecnologicos <- c("Elsby, et al. (2015), Lubik (2013)")
autores_ciclo <- c("Abraham y Watcher (1987)", "Blanchard y Diamond (1989)", "Hobijn y Şahin (2013)")

tabla <- data.table::data.table(
                    Factores = factores,
                    Autores = list(autores_institucionales, autores_tecnologicos, autores_ciclo)
                    )
```


## Agrupación

```{r echo=FALSE}
DT::datatable(tabla, rownames = FALSE, options = list(dom = "t", pageLength = 3, 
                initComplete = DT::JS(
                  
    "function(settings, json) {",
    "$(this.api().table().header()).css({'background-color': '#000', 'color': '#fff'});",
    "}")))
```

Otra opción es ver cuales son factores que pueden incidir en el aumento del desempleo de largo plazo: Mismatch, seguros de desempleo extendidos, incertidumbre sobre las condiciones económicas `r Citep(myBib, "Daly2012")`

---
name: cb-2
class: top

## Teoría de Búsqueda y Emparejamiento

Inicios: `r Citet(myBib, "Hall1979")`, `r Citet(myBib, "Pissarides1979")`, `r Citet(myBib, "Diamond1982B")`. <b>Marco DMP</b>:  `r Citet(myBib, "Diamond1982")`, `r Citet(myBib, "Pissarides1985")`, `r Citet(myBib, "Mortensen1994")`, `r Citet(myBib, "Pissarides2000")`.

--

* Modelo básico se representa de la siguiente forma:

\begin{align}
u &= \frac{\lambda}{\lambda+\theta q(\theta)} & \quad \text{CB-BC} \\
p - w  - \frac{(r+\lambda)pc}{q(\theta)} & = 0  &\quad JC \\
w & = (1 - \beta)z + \beta p(1 + c\theta) & \quad WC
\end{align}

El equilibrio del modelo es una asignación (u, $\theta$, v) que satisface la condición de equilibrio de los flujos representando por la BC, JC y la WC.

--


```{r curvasEQ, echo=FALSE, fig.cap="Equilibrio del mercado laboral", fig.height=3, fig.width=8}

curvas <- data.table(v = seq(1, 25, 1),
                     u = seq(1, 25, 1))
create_curves <- function(title_curva1, title_curva2, theta, x_axis, y_axis) {
ggplot(curvas, aes(x = u, y = v)) +
    geom_line() +
    geom_line(aes(x = (1:25) + 1, y = 20/(u))) +
    scale_x_continuous(limits = c(0,20)) +
    scale_y_continuous(limits = c(0,20)) + 
    geom_text(aes(label = title_curva1, y = .5, x = 12)) +
    geom_text(aes(label = title_curva2, y = 20, x = 12)) +
    {if(theta) {
        annotate('text', x = 2.5, y = 0.5, 
                 label = "theta",parse = TRUE,size=5)  
    }} +
    {if(theta) {
    geom_curve(x = -1, xend = 2, y = 2, yend = -1, curvature = -0.5, angle = 90)
    }} +
    labs(x = x_axis, y = y_axis) +
    # geom_segment(aes(x=0, xend = 20 , y=0, yend = 0), size=1.5,
    #              arrow = arrow(length = unit(0.6,"cm"))) +
    theme(
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour="black"), 
        axis.ticks = element_blank())
}
p1 <- create_curves(title_curva1 = "Curva de Beveridge", title_curva2 = "Creación de trabajo", 
              theta = TRUE, x_axis = "u", y_axis = "v")
p2 <- create_curves(title_curva1 = "Creación de trabajo", title_curva2 = "Curva salarial", 
              theta = FALSE, y_axis = "w", x_axis = expression(theta))
p1 + p2
```


<!-- - La teoría de búsuqueda y emparejamiento resumida en `r Citet(myBib, "Pissarides2000")` plantea que los movimientos sobre la curva se asocian a factores de ciclo económico mientras traslados paralelos se interpretan como cambios estructurales que afectan el _matching_ entre puestos y trabajadores desempleados. -->

<!-- - Los traslados pueden ser por aumentos en la tasa de destrucción de puestos laborales o modificaciones en la función de matching. -->

<!-- - Cambios en la función de matching pueden deberse a cambios en los costos de contratación, despido, seguro de desempleo y salario mínimo `r Citep(myBib, "Bouvet2012")`, existencia de derecho a huegla, ocupación y sindicalización `r Citep(myBib, "Nickell2002")`, facilidad de la mano de obra para moverse geográficamente `r Citep(myBib, "Bewley1979")`, `r Citep(myBib, "Hobijn2013")`, modificaciones en el comportamiento de las firmas `r Citep(myBib, "Haltiwanger2012")` y alteraciones tecnológicas que puedan cambiar los costos de búsqueda y la probabilidad de encontrarse `r Citep(myBib, "Barnichon2012")`, `r Citep(myBib, "Elsby2015")` -->

???
Notas para mi que no puede ver el resto.

<!-- --- -->
<!-- name:cb-4 -->
<!-- template:cb -->

<!-- ## Este trabajo -->

<!-- * Utiliza estrategías empíricas flexibles que puedan captar cambios continuos o discretos (media y/o varianza) -->
<!-- * Exploración: -->
<!--   + Test de fluctuación generalizada -->
<!--   + Test de quiebres estructurales de tipo F generalizados -->
<!-- * Aplicación: -->
<!--   + Test F generalizados con múltiples quiebres -->
<!--   + TVP-VAR-SV (Vectores Autorregresivos de parámetros variables y volatilidad estocástica) -->
<!--       + Identificado bajo Modelos de Búsqueda y Cholesky, estimado de forma bayesiana (Gibbs) -->
<!-- * Seguimos los trabajos de:  -->
<!--   + `r Citet(myBib, "Primiceri2005")`, `r Citet(myBib, "Benati2013")`, `r Citet(myBib, "Lubik2013")`, `r Citet(myBib, "Lubik2016")` -->
<!--   + Verificamos y generalizamos los resultados de `r Citet(myBib, "Urrestarazu1997")` -->

---
name: datos-inicio
class: center, middle, presentation-slide, seccion-slide
background-image: url(assets/fuentes-datos-fondo.png)
background-size: contain
count: false

# .largest[[Fuentes de datos utilizadas en el proyecto](#inicio)]

---
name: datos

###### [Fuentes de datos](#inicio)

---
name: datos-1
template: datos
class: no-logo-slide

```{r include=FALSE}
tabla <- data.table::data.table(Nombre = c(rep("Avisos laborales", 11), "PEA", "ECH", "Tasa desempleo", "Encuesta Internet", "PIB"),
                    Fuente = c(rep("Gallito", 6), "Buscojobs", "Computrabajo", "Gallito", "Buscojobs", "Computrabajo", "INE", "INE", "INE", "RADAR", "BCU"),
                    Extraida = c("Urrestarazu (1997)", "Biblioteca Nacional", "Biblioteca Nacional", "CERES", "Espino, Goinheix, and Alves (2011)", "Diario El País", "WaybackMachine", "WaybackMachine", "Portal Gallito", "Portal Buscojobs", "Portal Computrabajo", "Urrestarazu (1997)", "IECON", "INE", "RADAR", "CINVE"),
                    Periodo = (c("1980-1995", "1995-1998", "1999, 2000, 2009Qi:2014Qi", "1998-2014", "2000-2009", "2013-2018", "2007-2018", "2003-2018", "2018-2019", "2019", "2018-2019", "1980-1995", "1980-2018", "1981-2019", "2015-2016", "1980-2019")))
```


```{r echo=FALSE}
DT::datatable(tabla, options = list(dom = "t", pageLength = 16, 
                initComplete = DT::JS(
    "function(settings, json) {",
    "$(this.api().table().header()).css({'background-color': '#000', 'color': '#fff'});",
    "}")))
```

---
name: estrategias-inicio
count: false
class: center, middle, presentation-slide, seccion-slide

# .largest[[Estrategías empíricas](#inicio)]

---
name: estrategias

###### [Estrategías Empíricas](#inicio)

---
name: estrategias-svar
template: estrategias

## VAR con parámetros variables y volatilidad estocástica

`r Citep(myBib, "Primiceri2005")` propone el siguiente modelo para un vector n-dimensional $y_t$:

$$\begin{equation}
y_t = c_t + B_{1,t}y_{t-1} + ...+ B_{k,t}y_{t-k} + u_t \ \ \ \ t = 1,....T \quad (1)
\end{equation}$$

Donde $y_t$ n x 1; $c_t$ n x 1; $B_{i,t}$, $i = 1,....k$, son matrices n x n; $u_t$ son shocks inobservables, heterocedásticos con matriz de varianzas y covarianzas $\Omega_t$. 

Consideremos una reducción triangular de $\Omega_t$ definida por:

$$\begin{equation}
A_t\Omega_tA_t' = \Sigma_t\Sigma_t'
\end{equation}$$

Con $A_t$ una matriz triangular inferior con elementos $\alpha_{ij,t}$ y unos en su diagonal. $\Sigma_t$ una matriz diagonal de elementos $\sigma_{i,t}$. El modelo (1) pasa a ser:

\begin{align}
y_t &= c_t + B_{1,t}y_{t-1} + B_{2,t}y_{t-2} + ... + B_{p,t}y_{t-p} + A_t^{-1}\Sigma_t\epsilon_t \quad (2) \\
V(\epsilon_t) &= \mathbb{I}_t \notag
\end{align}

Apilando con el operador $vec$ todos los coeficientes del lado derecho de la ecuación (2) en un vector $B_t$, se puede reescribir el modelo.

\begin{align}
y_t  &= X_t'B_t + A_t^{-1}\Sigma \epsilon_t \quad (3)
\end{align}

Donde $X_t' = I_n \otimes [1, y_{t-1}, ..., y_{t-p}]$ con $\otimes$ denotando el producto de Kronecker. Con $y_t$ nx1 y $B_t$ contiene los $\{B_{j,t}\}_{j=1}^p$ y los $c_t$ de la ecuación (2).

---
name:estrategias-svar2
template: estrategias

## VAR con parámetros variables y volatilidad estocástica

La estrategia de identificación consiste en modelar los coeficientes de la ecuación (3) en lugar de (1). El modelo VAR completo es:

\begin{align}
y_t  &= X_t'B_t + A_t^{-1}\Sigma\epsilon_t    & \quad (4) \\
B_t &= B_{t-1} + \nu_t                        & \quad (5) \\
\alpha_t &= \alpha_{t-1} + \zeta_t            & \quad (6) \\
log \ \sigma_t &= log \ \sigma_{t-1} + \eta_t & \quad (7)
\end{align}

<!-- La dinámica del modelo se resume en las ecuaciones (5) a (7), donde $\alpha_t$ es el vector de elementos no negativos y no unos de la matriz $A_t$ los cuales están apilados por filas mediante el operador $vec$  -->
<!-- mientras $\sigma_t = diag(\Sigma)$.  -->
<!-- Los elementos de $B_t$ se modelan como paseos aleatorios, supuestos que puede ser relajado, al igual que los elementos de la matriz $A_t$.  -->
<!-- Se supone que los desvíos estándar $\sigma_t$ evolucionan como un paseo aleatorio geométrico, lo cual lo hace pertenecer a la clase de modelos con volatilidad estocástica. -->

La matriz de varianzas y covarianzas (VCV) de los residuos varía en el tiempo debido al término de error compuesto $A_t^{-1}\Sigma_t\epsilon_t$. Con $\epsilon_t$ siguiendo una distribución normal n-dimensional y $\{\nu, \zeta_t, \eta_t\}$ vectores normales homocedásticos, de media cero y mutuamente independientes.

Las innovaciones en el modelo se asume tienen una distribución normal conjunta con la siguiente matriz de varianzas y covarianzas:

\begin{align}
V = Var 
\begin{pmatrix} 
\epsilon_t \\ \nu_t \\ \zeta_t \\ \eta_t 
\end{pmatrix} = \begin{pmatrix}
\mathbb{I}_n \ 0 \ 0 \ 0\\
0 \ Q \ 0 \ 0 \\
0 \ 0 \ S \ 0 \\
0\ 0\ 0\ W \end{pmatrix}
\end{align}

Donde $\mathbb{I}_n$ es una matriz identidad n-dimensional, Q, S, W son matrices semidefinidas positivas.

<!-- Para poder estudiar los efectos de un shock de productividad desde el producto al desempleo y vacantes, se computan las funciones de impulso respuesta (FIR). En el caso de un VAR de parámetros fijos, el computo de las FIR son independientes al proceso de estimación del modelo, mientras en un TVP-VAR ambas etapas son dependientes y se obtiene una FIR para momento del tiempo. -->

---
name: estrategias-quiebres0
template: estrategias

## Quiebres estructurales

\begin{equation}
y_i = x_i^T\beta_i + u_i\space\space\space\space (i= 1...n)
\end{equation}

<!-- Para cada momento i, $y_i$ es la variable dependiente, $x_i = (1, x_{i2}, ..., x_{ik}^T)$ es un vector $k \times 1$ con $k-1$ observaciones de regresores o variables independientes. Los $u_i$ son $iid(o, \sigma^2)$ y $\beta_i$ es un vector k variado de parámetros.  -->

\begin{equation}
\beta_i = \begin{cases} \beta_A &(1 \leq i \leq i_0) \\ \beta_B &(i_0 < i \leq n) \end{cases}
\end{equation}

Con $i_0$ es algún punto en el intervalo $(k, n-k)$. 
<!-- Posteriormente son extendidos para no especificar el momento de quiebre, sino un intervalo de tiempo.  -->
Extensión: Se utiliza una secuencia de estadísticos F para un quiebre en un momento i, se calculan los residuos de ese segmento $\hat{u}_i$ (una regresión para cada submuestra) y se comparan con los residuos de un modelo sin quiebres.

$$\begin{equation}
F_{i} = \frac{\hat{u}^T\hat{u}-\hat{e}(i)^T\hat{e}(i)} {\hat{e}(i)^T\hat{e}(i)/(n-2k)}
\end{equation}$$

<!-- Es posible plantear límites para el estadístico F. Asumiendo $H_0$, los límites se pueden calcular de tal forma que la probabilidad asintótica de alguna forma de agregación de los distintos estadísticos F calculados sobre los intervalos considerados $\underline i \leq i \leq \bar{i}$, superen dicho umbral con una significación $\alpha$.  -->

`r Citet(myBib, "Andrews1993", "Andrews1994")` plantean utilizar los funcionales: supremo, media o exponencial. Se plantean tres estadísticos para testear H0:

\begin{align}
supF &= \sup_{\underline i \leq i \leq \bar{i}} F_i \\
aveF &= \frac{1}{\bar{i} - \underline i + 1}\sum_{i = \underline i}^{\bar{i}}F_i \\
expF &= log \left( \frac{1}{\bar{i}-\underline i + 1}\sum_{i = \underline i}^{\bar{i}}exp(0.5\times F_i) \right)
\end{align}

Si sucede que el funcional supera dicho umbral, existe evidencia de un cambio estructural con una significación $\alpha$. 

---
name: estrategias-quiebres2
template:estrategias

## Extensión a múltiples quiebres. 

Dadas m particiones $i_1$ a $i_m$ se obtienen los $\beta_j^{MCO}$. La mínima RSS es:

$$RRS(i_1,...i_m) = \sum_{j=1}^{m+1}rss(i_{j-1}+1, i_j)$$
<!-- Con $rss(i_{j-1}+1, i_j)$ la mínima rss en el segmento j. -->

El problema es encontrar los quiebres $\hat{i_1}, ..., \hat{i_m}$ que minimicen la función objetivo:
$$(\hat{i_1}, ..., \hat{i_1}) = arg\min_{i_1,...i_m} RSS(i_1, ...i_m)$$
Sobre todas las particiones $i_1...i_m$, con $i_j - i_{j-1} \geq n_h \geq k$. 
Obtener el minimizador global con grid search es de orden $O(n^m)$.

Extensión, `r Citet(myBib, "BaiPerron1998", "BaiPerron2003")` algoritmo de programación dinámica $O(n^2)$. Sea $RSS(\{T_{m,n}\})$ la suma de cuadrados de residuos asociada con la partición optima conteniendo $m$ quiebres usando las primeras n observaciones. La partición óptima resuelve el siguiente problema recursivo:

$$RSS(\{T_{m,T}\}) = \min_{mn_h\leq i\leq n-n_h}[RSS(\{T_{m-1,j}\}) + RSS(\{i+1, n\})]$$

`r Citet(myBib, "Zeileis2010")` extiende incluyendo el error de la varianza como un regresor adicional y estima el modelo por MV o QMV. El modelo planteado es cuasi-normal y tiene densidad:

$$f(y|x,\beta, \sigma^2) = \phi((y-x^T\beta)/\sigma)/\sigma$$
Donde $\phi(.)$ es la función de densidad de una normal estándar. Con $\theta = (\beta^T, \sigma^2)^T$ de largo $k = c +2$, siendo c la cantidad de regresores, más intercepto y varianza.

---
name: resultados-inicio
class: center, middle, presentation-slide, seccion-slide
background-image: url(assets/vacantes.gif)
background-size: contain
count: false

# .largest[[Resultados](#inicio)]

---
name: resultados

###### [Resultados](#inicio)

---
name: resultados-0
template:resultados

## Construcción del indicador de vacantes:

El objetivo es obtener una aproximación de la cantidad de avisos totales, por ello primero es necesario obtener $a_t$ desde el índice de vacantes `r Citet(myBib, "Urrestarazu1997")`. Sin embargo, la base de dicho índice es 1980 y los datos disponibles en el trabajo son desde 1981 en adelante. El índice esta expresado en función de la PEA:
\begin{equation}
v_t = \frac{\frac{a_t}{a_0}}{\frac{PEA_t}{PEA_0}}
\end{equation}

No se conoce $a_0$ ni $PEA_0$, ni se tienen datos de 1980. Por lo cual, se siguen los siguientes pasos:

1. Obtener $a_t$ en algún punto: $a_{1995_q4}$
2. Imputar la PEA hacia atrás, obteniendo $pea_{t=0}$.
3. Despejar $a_{t=0}$ de 
$v_t$ = $(a_t/pea_t)/(a_{t=0}/pea_{t=0})100$.
4. Obtener la base $\alpha$ = $a_{t=0}$ / $pea_{t=0}$.
5. Imputar las vacantes hacía atrás.
6. Calcular la serie de avisos

Luego:

1. Generar la serie de Buscojobs
2. Generar la serie de Computrabajo
3. Unir las series

¿Cómo?

* Scraping, imputación (filtro de kalman suavizado) y _text mining_

---
name: resultados-1
background-image: url(assets/series-conjuntas-1-1.png)
background-size: contain
class: top, center

#### <b>Series de vacantes laborales</b>

---
name: resultados-2
background-image: url(assets/serie-final-gallito-1-1.png)
background-size: contain
class: top, center

#### <b>Unión de vacantes laborales</b>

???
¿Cómo pasamos de las tres series a una sola? Text-Mining y calculo de similaridad.

---
name: resultados-3
background-image: url(assets/IndiceVacantesAvisos-1-1.png)
background-size: contain
class: top, center

#### <b>Índice de avisos y vacantes laborales</b>

---
name: resultados-bc-gif
template: resultados
background-image: url(assets/CB_anual.gif)
background-size: contain


---
name: resultados-bc
template: resultados

## Curva de Beveridge

```{r beveridge-curve, fig.cap="Curva de Beveridge 1981-2018", fig.ncol = 2, echo = FALSE}
dt <- readRDS(here::here("Datos", "Finales", "series_version_final.rds"))

y_lim <- c(0.1, 1.2)
x_lim <- c(5, 20)
p1 <- ggplot(dt[data.table::between(fecha, "1981-01-01", "2018-10-01"),], aes(y = ind_vac, x = td)) + 
    geom_point() +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10), limits = y_lim) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 10), limits = x_lim) +
    geom_path() +
    labs(x = "Tasa de desempleo", y = "Índice de vacantes", title = "Panel A. Datos trimestrales") +
    coord_fixed(ratio = 20) +
    theme_Publication()

p3 <- dt[data.table::between(fecha, "1981-01-01", "2018-10-01"), 
         .(td = mean(td), ind_vac = mean(ind_vac), pib = mean(pib), decada = unique(decada), 
           ano2 = gsub(pattern = "\\d{2,2}(\\d{2,2})", replacement = "\\1", x = ano)), 
         keyby = .(ano)] %>%
    ggplot(., aes(y = ind_vac, x = td, label = ano2)) + 
    geom_point() +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10), limits = y_lim) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 10), limits = x_lim) +
    geom_path() +
    ggrepel::geom_text_repel(fontface = "bold", size = 2, position=position_jitter(width=.1,height=.02), color = "black") +
    labs(x = "Tasa de desempleo", y = "Índice de vacantes", title = "Panel B. Datos Anuales") +
    coord_fixed(ratio = 20) +
    theme_Publication()
# patchwork
(p1 + p3)
```

---
name: resultados-5
template: resultados

## Estimación para los cuatro periodos detectados

```{r BCtest, fig.cap="Curva de Beveridge por periodos", fig.align="center", fig.width=12, fig.height=6, echo = FALSE}
dt$decada <- factor(dt$decada, levels = c(80, 90, 2000, 2010))
ochenta        = "gray"
noventa        = "orange"
dos_mil        = "darkgreen"
dos_mil_diez   = "skyblue"
color_decada <-  c(ochenta, noventa, dos_mil, dos_mil_diez)
dt[fecha <= "1990-04-01", decada_test := "1-periodo"
   ][between(fecha, "1990-07-01", "1996-04-01"), decada_test := "2-periodo"
     ][between(fecha, "1996-07-01", "2013-04-01"), decada_test := "3-periodo"
       ][between(fecha, "2013-07-01", "2019-10-01"), decada_test := "4-periodo"]
dt$decada_test <- factor(dt$decada_test,labels = c("81-90:Q4", "90:Q3-96:Q2", "96:Q3-2013:Q2", "2013:Q3-2018:Q4"))

ggplot(dt, aes(y = ind_vac, x = td, color = decada_test)) + 
    geom_point() +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
    labs(x = "Tasa de desempleo", y = "Índice de vacantes", title = " \n ") +
    scale_color_manual(name = "", values = color_decada) +
    geom_smooth(method = "lm", formula = y ~ x) +
    theme_Publication()
```


---
name: resultados-4
template: resultados
background-image: url(assets/coeficientes-cada-periodo.png)
background-size: contain
class: center, top

## Estimación para los cuatro periodos detectados

---
name: resultados-6
template: resultados

```{r FuncionesTVPVAR, echo = FALSE}
impulse_response <- function (fit, impulse.variable = 1, response.variable = 2, 
    t = NULL, nhor = 20, scenario = 2, draw.plot = TRUE, ..main = .main) 
{
    Beta.draws <- fit$Beta.draws
    nd <- dim(Beta.draws)[3]
    if (is.null(t)) 
        t <- dim(Beta.draws)[2]
    out <- matrix(0, nd, nhor + 1)
    M <- fit$M
    p <- fit$p
    H.sel <- fit$H.draws[, ((t - 1) * M + 1):(t * M), ]
    A.sel <- fit$A.draws[, ((t - 1) * M + 1):(t * M), ]
    if (scenario == 3) {
        sig <- apply(exp(0.5 * fit$logs2.draws), 1, mean)
        sig <- diag(sig)
    }
    else {
        sig <- NULL
    }
    for (j in 1:nd) {
        if (scenario == 1) {
            H.chol <- NULL
        }
        else if (scenario == 2) {
            H.chol <- t(chol(H.sel[, , j]))
        }
        else if (scenario == 3) {
            H.chol <- t(solve(A.sel[, , j])) %*% sig
        }
        aux <- bvarsv:::IRFmats(A = bvarsv:::beta.reshape(Beta.draws[, t, j], 
            M, p)[, -1], H.chol = H.chol, nhor = nhor)
        aux <- aux[response.variable, seq(from = impulse.variable, 
            by = M, length = nhor + 1)]
        out[j, ] <- aux
    }
    if (draw.plot) {
        pdat <- t(apply(out[, -1], 2, function(z) quantile(z, 
            c(0.05, 0.25, 0.5, 0.75, 0.95))))
        xax <- 1:nhor
        matplot(x = xax, y = pdat, type = "n", ylab = "", xlab = "Horizonte", bty = "n", xlim = c(1, nhor))
        polygon(c(xax, rev(xax)), c(pdat[, 5], rev(pdat[, 4])), 
            col = "grey60", border = NA)
        polygon(c(xax, rev(xax)), c(pdat[, 4], rev(pdat[, 3])), 
            col = "grey30", border = NA)
        polygon(c(xax, rev(xax)), c(pdat[, 3], rev(pdat[, 2])), 
            col = "grey30", border = NA)
        polygon(c(xax, rev(xax)), c(pdat[, 2], rev(pdat[, 1])), 
            col = "grey60", border = NA)
        lines(x = xax, y = pdat[, 3], type = "l", col = 1, lwd = 2.5)
        abline(h = 0, lty = 2)
        title(main = ..main, cex.main = 0.6, adj = 0, line = 0)
    }
    list(contemporaneous = out[, 1], irf = out[, -1])
}
# Carga del modelo svar-sv
fit <- readRDS(here::here("Datos", "Finales", "modelo.rds"))

# Función para generar los gráficos de parámetros y varianzas
matplot2 <- function(...) matplot(..., type = "l", lty = 1, lwd = 2, bty = "n", ylab = "")
stat.helper <- function(z) c(mean(z), quantile(z, c(0.16, 0.84)))[c(2, 1, 3)]
gp <- seq(1985, 2020, 5) # marks for vertical lines
# colors, taken from http://www.cookbook-r.com
cols <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cols1 <- cols[c(2, 4, 2)]
make_plot <- function(.fit = fit, .type = "vcv", .var = 1, .title = "") {
    gp <- seq(1990, 2020, 5) # marks for vertical lines
    if(.type == "vcv") {
        # SD of unemployment residual
        # Get posterior draws
        sd_inf <- parameter.draws(.fit, type = .type, row = .var, col = .var)
        x1     <- t(apply(sqrt(sd_inf), 2, stat.helper))    
    } else if (grepl(x = .type, pattern = "lag")) {
        beta <- parameter.draws(fit, type = .type, row = .var, col = .var)
        x1   <- t(apply(beta, 2, stat.helper))    
    } else {
        beta_0 <- parameter.draws(fit, type = .type, row = .var, col = .var)
        x1     <- t(apply(beta_0, 2, stat.helper))       
    }
    xax <- seq(1990, 2018, length.out = NROW(x1)) # x axis
    # Plot
    if(.type == "vcv") {
        var <- sd.residuals.ols[.var]
    } else {
        var <- NULL
    }
    matplot2(x = xax, y = x1, ylim = c(min(x1), max(x1)), col = cols1, main = .title , xlab = "")
    # abline(h = seq(min(x1), max(x1), length.out = 10), v = gp, lty = 4, lwd = 0.3)
    if(.type == "vcv") {
        abline(h = var, col = cols[1], lwd = 1.4, lty = 5)
    }
}

# Función para generar los IRF
plot_irf <- function(.fit = fit, impulse, response, scenario = 2, .main = "") {
    ira <- impulse_response(fit, impulse.variable = impulse, response.variable = response, scenario = scenario, ..main = .main)
    # OLS impulse responses for comparison
    ira.ols <- irf(fit.ols, n.ahead = 20)[[impulse]][[response]][-1, 1]
    # Add to plot
    ira.ols
    lines(x = 1:20, y = ira.ols, lwd = 1, lty = 5, col = "red")
}

# carga del modelo var
library(vars)
fit.ols <- readRDS(here::here("Datos", "Finales", "modelo-var-comun.rds"))
sd.residuals.ols <- apply(residuals(fit.ols), 2, sd)
```

```{r svar-parameters, fig.cap="Rezagos, coeficientes y volatilidades modelo TVP-VAR. Fila 1 son los coeficientes, fila 2 los rezagos y fila 3 varianzas.", fig.height=6, fig.width=8, fig.align="center", echo = FALSE}
library(bvarsv)
par(mfrow = c(3, 3))
for(i in c("intercept", "lag1", "vcv")) {
    for(j in 1:3) {
      if(j == 1) k <- "pib" else if (j == 2) k <- "vacantes" else k <- "desempleo"
      if (i == "intercept") {
        k <- eval(bquote(expression(.(k) ~ c[j][t])))
      } else if (i == "lag1") {
        k <- eval(bquote(expression(.(k) ~ B[j][t])))
      } else {
        k <- eval(bquote(expression(.(k) ~ Sigma[j][t])))
      }
      make_plot(.fit = fit, .type = i, .var = j, .title = k)
    }
}
```

---
name: tvp-var-k
template: resultados

```{r FIR, fig.cap="FIR TVP-VAR", echo = FALSE}
par(mfrow = c(1, 2))
plot_irf(impulse = 1, response = 2, .main = "Panel A. Vacantes")
plot_irf(impulse = 1, response = 3, .main = "Panel B. Desempleo")
```

---
name: tvp-var-n
template: resultados

```{r FIRs, fig.cap="FIR diferentes años", echo = FALSE}
abline2 <- function(...){ 
    abline(..., lty = 4, lwd = 0.3)
}
fir_periodos <- function(fit, respuesta, impulso = 1, titulo) {
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cols1 <- cbPalette#[c(2, 4, 2)]
cols2 <- cbPalette#[c(2, 4, 6)]

fir <- list()
j = 0
for(i in seq(1, 100, 8)) {
    j = j + 1
    fir[[j]] <- impulse.responses(fit, 
                      impulse.variable = impulso, 
                      response.variable = respuesta, 
                      t = i, scenario = 2, 
                      draw.plot = FALSE)$irf
}

gdat <- rbind(0, sapply(fir, function(z) apply(as.matrix(z), 2, median))) 

yb <- c(min(gdat), max(gdat))
matplot2(x = 0:20, y = gdat, ylim = yb, xlab = "Horizonte",
         col = cols2) 
title(main = titulo, cex.main = 0.6, adj = 0, line = 0)
abline2(v = seq(5, 20, 5), h = seq(yb[1], yb[2], (yb[2]-yb[1])/10)) # 0.0001
}
par(mfrow = c(1, 2))
fir_periodos(fit = fit, respuesta = 2, impulso = 1, titulo = "Panel A. Vacantes")
fir_periodos(fit = fit, respuesta = 3, impulso = 1, titulo = "Panel B. Desempleo")
```

---
name: discusion-inicio
class: center, middle, presentation-slide, seccion-slide
count: false

# .largest[[Discusión](#inicio)]

---
name: discusion

###### [Discusión](#inicio)

---
name: discusion-vacantes
template: discusion

### Indicador de vacantes

* Serie de avisos no de puestos
  + [1996-1998 comparativa](#discusion-avisos-puestos)
  + [2000-2010 comparativa](#discusion-avisos-puestos-2)
* Avisos que se repiten en el tiempo
  + [Avisos Gallito 2014-2018](#discusion-avisos-repetidos)
* ICDL
  + [Comparación ICDL y Espino, et al (2012)](#discusion-avisos-ceres-iecon)
* Serie de Montevideo
  + [Avisos por portal laboral y departamento](#discusion-avisos-dpto)
* Sesgo a puestos de baja calificación e informalidad.
* Relación positiva/negativa con el PIB

## [Siguiente: Estimaciones](#discusion-estimaciones)

---
name: discusion-avisos-puestos
class: bottom

###### [Volver](#discusion-vacantes)

## Avisos laborales

```{r AvisosPuestos, fig.cap = "Avisos y puestos laborales Gallito 1996-1998", message=FALSE, warning=FALSE, paged.print=FALSE, fig.height=6, fig.width=10, echo = FALSE}
molina <- readxl::read_xlsx(here::here("Datos", "Originales", "Gallito-1996-1998.xlsx"), col_names = TRUE, sheet = "avisos_puestos", na = c(" ", ""))
data.table::setDT(molina)
molina$puestos_tot <- ifelse(molina$subseccion != "avisos destacados", molina$avisos, molina$total_puestos)
molina[data.table::year(f_ini) > 1995, 
       .(av = sum(avisos, na.rm = T),
         av_filtro = sum(puestos_tot, na.rm = TRUE),
         fecha = as.Date(paste(ano, mes, 1, sep = "-"))), 
       keyby = .(ano = data.table::year(f_fin), mes = data.table::month(f_fin))
       ][, ggplot(.SD) +
             geom_line(aes(x = fecha, y = av)) +
             geom_line(aes(x = fecha, y = av_filtro), linetype = "dashed") +
             geom_point(aes(x = fecha, y = av)) +
             geom_point(aes(x = fecha, y = av_filtro)) +
             scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
             scale_x_date(date_breaks = "3 month", date_labels = "%y %b") +
           geom_text(aes(label = "- - - Puestos", y = 5000, 
                         x = as.Date("1996-03-01")), color = "black") +
       geom_text(aes(label = "--- Avisos", y = 5500, 
                     x = as.Date("1996-03-01")), color = "black") +
             labs(y = "Cantidad", x = "Fecha") +
             theme_Publication(position_legend = "bottom")
         ]
```

---
name: discusion-avisos-puestos-2
class: bottom

###### [Volver](#discusion-vacantes)

## Avisos laborales

```{r iecon-avisos-puestos, fig.cap="Serie Gallito 2000-2009", fig.align="center", fig.height=6, fig.width=10, echo = FALSE}
iecon <- haven::read_dta(here::here("Datos", "Originales", "Gallito-2000-2009.dta"))
iecon$fecha <- as.Date(paste(iecon$aniog,iecon$mesg, iecon$diag, sep = "-"))
iecon_ts <- iecon %>% 
    dplyr::group_by(aniog, mesg) %>% 
    dplyr::summarise(puestos = sum(puestos, na.rm = TRUE),
                            avisos = dplyr::n())
iecon_ts$fecha <- as.Date(paste(iecon_ts$aniog, iecon_ts$mesg,"1", sep = "-"))
iecon_ano <- iecon %>% 
                dplyr::group_by(fecha = lubridate::make_date(aniog)) %>%                          dplyr::summarise(puestos = sum(puestos, na.rm = TRUE),
                                 avisos = n())
ceres <- readxl::read_xls(here::here("Datos", "Originales", "ICDL-1998-2014.xls"),
                          col_names = TRUE, sheet = "serie", 
                          col_types =c("date","numeric"),
                          readxl::cell_cols("A:B"))
ceres_ts <- ts(data = ceres[,2], start = c(1998,3), frequency = 12)
ceres_ano <- 
    ceres %>% 
        dplyr::group_by(fecha = lubridate::make_date(lubridate::year(fecha))) %>%
        dplyr::summarise(ind_vacantes = mean(vacantes, na.rm = TRUE))

ggplot(data = iecon_ts, aes(x = fecha, y = avisos)) +
    geom_line() +
    geom_point() +
    geom_line(aes(y = puestos), linetype = "dashed") +
    geom_point(aes(y = puestos)) +
    scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
    scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
    geom_text(aes(label = "- - - Puestos", y = 300, 
                         x = as.Date("2009-01-01")), color = "black") +
    geom_text(aes(label = "--- Avisos", y = 400, 
                     x = as.Date("2009-01-01")), color = "black") +
    labs(y = "Cantidad", x = "Fecha") +
    theme_Publication()
```

---
name: discusion-avisos-dpto

###### [Volver](#discusion-vacantes)

## Avisos laborales por departamento y portal laboral

```{r avisos-dpto, fig.cap="Avisos recolectados mediante scraping", fig.align='center', fig.height=6, fig.width=10, echo = FALSE}

av_comp <- readRDS(here::here("Datos", "Finales", "AvisosCompatibilizados.rds"))
dd <- av_comp[ano == 2019, .N, by = .(pagina, dpto)]
dd[, ord  := data.table::frank(.SD, N, ties.method = "first")]
dd[, prop := N/sum(N), by = pagina]
dd[, dpto := dplyr::case_when(
  dpto == "montevideo" ~ "Montevideo",
  dpto == "canelones" ~ "Canelones",
  dpto == "cerrolargo" ~ "Cerro Largo",
  dpto == "paysandu" ~ "Paysandú",
  dpto == "maldonado" ~ "Maldonado",
  dpto == "durazno" ~ "Durazno",
  dpto == "soriano" ~ "Soriano",
  dpto == "sanjose" ~ "San José",
  dpto == "colonia" ~ "Colonia",
  dpto == "rocha" ~ "Rocha",
  dpto == "lavalleja" ~ "Lavalleja",
  dpto == "florida" ~ "Florida",
  dpto == "rivera" ~ "Rivera",
  dpto == "salto" ~ "Salto",
  dpto == "otros" ~ "Otros",
  dpto == "rionegro" ~ "Río negro",
  dpto == "tacuarembo" ~ "Tacuarembó",
  dpto == "treintaytres" ~ "Treinta y Tres",
  dpto == "missing" ~ "Missing",
  dpto == "artigas" ~ "Artigas",
  dpto == "flores" ~ "Flores"
)]
dd[, pagina :=  dplyr::case_when(
  pagina == "buscojobs" ~ "Buscojobs",
  pagina == "gallito"   ~ "Gallito",
  pagina == "computrabajo" ~ "Computrabajo"
)]
ggplot(dd, aes(x = reorder(dpto, ord), y = prop)) +
           geom_bar(stat = "identity", fill = "black") +
           facet_wrap(~ pagina, scales = "free_x", drop = TRUE) +
           scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
           labs(y = "Avisos", x = "Departamento", title = " \n ") +
           theme_Publication(angulo_y = 0, angulo_x = 90)
```

---
name: discusion-avisos-repetidos

###### [Volver](#discusion-vacantes)

## Comparación avisos repetidos y sin repetir

```{r ga13-18-comparacion, fig.align="center", fig.cap="Avisos diario El País", echo = FALSE}
dt <- readRDS(here::here("Datos", "Finales", "series_version_final.rds"))
dt[data.table::between(fecha, "2013-07-01", "2018-10-01"), 
   ggplot(.SD) +
     geom_line(aes(x = fecha, y = av_ga_c_dup), linetype = "dashed") +
     geom_line(aes(x = fecha, y = av_ga_s_dup)) +
     geom_point(aes(x = fecha, y = av_ga_c_dup)) +
     geom_point(aes(x = fecha, y = av_ga_s_dup)) +
     scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
     scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
     geom_text(aes(label = "- - - Avisos con repetidos", y = 5800, 
                         x = as.Date("2018-01-01")), color = "black") +
     geom_text(aes(label = "─── Avisos sin repetidos", y = 5400, 
                     x = as.Date("2018-01-01")), color = "black") +
     labs(y = "Avisos", x = "Fecha") +
     theme_Publication()
  ]
```

---
name: discusion-avisos-ceres-iecon

###### [Volver](#discusion-vacantes)

## Comparación tasas de crecimiento avisos

```{r iecon-ceres, fig.cap="Comparación tasas de crecimiento", fig.align="center", echo = FALSE}
d <- data.table(fecha = seq.Date(from = as.Date("2001-01-01"), to = as.Date("2009-01-01"), by = "years"))
d[, ceres := ceres_ano$ind_vacantes[3:12] %>% log(.) %>% diff(.)
  ][, iecon_avisos  := iecon_ano$avisos %>% log(.) %>%  diff(.)
    ][, iecon_puestos := iecon_ano$puestos %>% log(.) %>%  diff(.)]
ggplot(d, aes(x = fecha)) +
  geom_point(aes(y = ceres)) +
  geom_line(aes(y = iecon_avisos), linetype = "dotted", color = "black") +
  geom_line(aes(y = iecon_puestos), linetype = "dashed", color = "black") +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  geom_text(aes(label = "- - -  Puestos, Espino, et al (2012)", y = 0.4, 
                         x = as.Date("2008-01-01")), color = "black") +
  geom_text(aes(label = "..... Avisos,  Espino, et al (2012)", y = 0.35, 
                     x = as.Date("2008-01-01")), color = "black") +
  geom_text(aes(label = "   • Avisos, CERES", y = 0.3, 
                     x = as.Date("2008-01-01")), color = "black") +
  labs(x = "Fecha", y = "Tasas de crecimiento") +
  theme_Publication()
```


---
name: discusion-estimaciones
template: discusion

### Estimaciones

* ¿Explicaciones?
  + Quiebre de 1990:
      + Institucional `r Citep(myBib, "Filgueira2003")`, `r Citep(myBib, "Quinones2001")`
      + Dezplazamiento de fuerza laboral `r Citep(myBib, "Hobijn2013", "Bewley1979")`

--

  + Quiebre hacia afuera de 1996:
      + Institucional (negociación y afiliados)`r Citep(myBib, "Filgueira2003")`
      + Productividad y Hrs `r Citep(myBib, "Quinones2001")` 
      + Informalidad y composición `r Citep(myBib, "Amarante2007", "Amarante2015")`
      
--

  + Quiebre hacia el origen de 2013:
      + Institucional (reglas de juego, salario mínimo, fricciones)  `r Citep(myBib, "Amarante2015", "Bergara2017")`, `r Citet(myBib, "Bouvet2012", "Nickell2002")`, `r Citep(myBib, "Hall2005")`.
      + Menor dinamismo (flujos) `r Citet(myBib, "Merlo2019")`
      + Intensidad de búsqueda `r Citep(myBib, "Haltiwanger2012")`
      + Procesos de contratación `r Citep(myBib, "Elsby2015")`
      
  <!-- + 1982 crisis de la tablita, elevada negociación por rama empresarial, vuelta de consejos de salarios y mayor presencia de sindicatos `r Citep(myBib, "Filgueira2003")`, `r Citep(myBib, "Quinones2001")`. -->
      
  <!-- + 1990 caída negociación por rama de actividad y cantidad de afiliados, no se convocan consejos de salarios `r Citep(myBib, "Filgueira2003")`. Ganancia de productividad, caída de horas trabajadas `r Citep(myBib, "Quinones2001")`, desempleo _elevado_ (8-10%), aumento de la informalidad al aumentar la proporción de ocupados en el sector servicios en conjunto a la caída de trabajadores en el sector manufacturero `r Citep(myBib, "Amarante2007")`, `r Citep(myBib, "Amarante2015")` y _fuerte_ crecimiento del producto hasta 1998. -->
  <!-- + Desplazamientos de la fuerza laboral (PEA) pueden reducir la eficiencia del matching `r Citep(myBib, "Hobijn2013")` y alterar la CB `r Citep(myBib, "Bewley1979")` (PEA 2004).  -->
  
  <!-- + Reformas estructurales iniciadas a partir de 2005, reforma tributaria del año 2007, aumento del salario mínimo sostenido `r Citep(myBib, "Amarante2015")`, convocatoria de los consejos de salarios, aumento de la negociación por rama de actividad, regulación del trabajo de servicio doméstico, ley de responsabilidad penal empresarial pudieron fomentar que PIT-CNT cuadruplique sus afiliados entre 2005 y 2020 `r Citep(myBib, "Bergara2017")`.  -->
      <!-- + Estos factores institucionales son similares a los identificados por `r Citet(myBib, "Bouvet2012", "Nickell2002")` y, pueden fundamentar el quiebre estructural de 1996-2013 (o el posible quiebre de 2004) y también el de 2013. -->
  
<!-- no es claro si reformas institucionales mejoraron o empeoraron el matching. Es posible plantear que favorecen a trabajadores y tiene efecto negativo en la medida que aumentan las fricciones del mercado laboral, como densidad sindical y salario mínimo `r Citep(myBib, "Hall2005")`, y comienzan a ser operativas a partir del fin de periodo de _bonanza_ de 2005-2012. -->
<!--       + `r Citet(myBib, "Merlo2019")` encuentra que tanto la destrucción como la creación de puestos de trabajo tiene una tendencia decreciente a partir de 2005, indicando un mercado laboral menos dinámico con un crecimiento neto de puestos decreciente.  QUE PERIODO USA???-->
<!--       + Sin embargo, podría suceder que las empresas alteren su comportamiento buscando mejores match y generen procesos de contratación más eficientes al aumentar su _intensidad de búsqueda_ `r Citep(myBib, "Haltiwanger2012")`. -->

<!--   + El traslado hacia el origen de la CB en 2013 podría deberse a cambios en los procesos de contratación `r Citep(myBib, "Elsby2015")`. A partir de 2008 los portales laborales comienzan a tener un flujo de avisos relevante.  -->

---
name: conclusiones

## [Conclusiones y trabajo futuro](#inicio)

---
name: conclusiones1
template: conclusiones

* Sistematización y creación de una base de datos de avisos laborales única en Uruguay. Trabajo permite extender el periodo de análisis y genera una herramienta para política económica.

--

* Importancia para la política económica:

--
  + Fuerte caída de la demanda laboral aproximada por las vacantes

--
  + Se observan un traslado hacia el origen ¿Mercado laboral más eficiente?
  
--
  + Traslado hacia el origen de la BC implicaría una tasa de desempleo natural menor
  
--
  + Aumentos recientes del desempleo se estarían asociando a factores cíclicos
  
--
  + Las reformas institucionales de los últimos 15 años no generan traslados hacia afuera, sino lo contrario.
  
--
  + Posibilidad de analizar el efecto de políticas laborales.
  
--
  + Analizar posible mismatch entre habilidades requeridas y solicitadas.

--
* Caída relevante (82-2002) en las vacantes. La única forma en que la economía soporte tal nivel de caída en la demanda laboral, es que el matching en el mercado laboral haya aumentado. 

--

* Quiebres estructurales:  4 quiebres que tienen sustento en transformaciones de la economía

--
* TVP-VAR-SV:
  + Constantes y rezagos no muestran variación (media), no así las matrices de varianzas y covarianzas. Periodo de cambio coincide con crisis de 2002. Se asocian los cambios a shocks
  + FIR (shocks de productividad) generan efectos de signo opuesto esperable sobre vacantes y desempleo.
  
--

* Factores relevantes en la CB: Avances tecnológicos (portales), intensidad de búsqueda (firmas), factores institucionales y de ciclo económico.


???

Es de hacer notar que las caídas observadas en las vacantes laborales son de orden similar a las observadas en 1982 y 2002, sin embargo la tasa de desempleo en ningún momento ha llegado a niveles similares.

La lectura sería que los traslados paralelos observados de la CB se deben a shocks con efectos significativos de signo opuesto. Si bien la economía ha tenido fuertes shocks externos, dada la cantidad de reformas que pueden catalogarse de estructurales, sería llamativo que la variabilidad en vacantes y desempleo pueda deberse solamente a innovaciones. Es posible profundizar sobre los modelos TVP-VAR, haciendo un análisis de priors y sus efectos, a la vez que probar y/o combinar diferentes restricciones de identificación y realizar el análisis con las series mensuales.

---
name: conclusiones2
template: conclusiones

<!-- Por lo que es necesario que trabajos futuros investiguen al respecto y agreguen análisis sobre los flujos laborales. -->

.large[
* Necesidad de identificar las causas que están detrás de los traslados de la CB para tomar acciones para mejorar la eficiencia del mercado laboral.
]
--

.large[
* Estimación de la curva JC para encontrar el equilibrio del mercado laboral en vacantes y desempleo. Obteniendo tasa natural de desempleo.]

--
* Perfeccionar indicador de vacantes:
  + Nuevas fuentes de información
  + Mejora de datos previos (Ej, 1998-2012)
  + Generar indicador de frecuencia mensual

--

* TVP-VAR, análisis de priors y sus efectos, a la vez que probar y/o combinar diferentes restricciones de identificación

--

* Modelo DSGE

--

* Calcular ciclo de la serie de vacantes mediante la aplicación del filtro de Hamilton y hacer un análisis conjunto con PIB y desempleo en el dominio de frecuencias, para analizar en que etapa del ciclo se encuentra la demanda laboral.

--

* Utilizar Wavelets para analizar tiempo y frecuencia de forma de profundizar en los cambios en la relación vacantes-pib.

???
Las agencias de contratación (y los mismos portales) pueden manejar enormes volúmenes de información sobre posibles candidatos que permiten una búsqueda sobre un universo mayor e incluso de forma selecta


---
name: referencias

## [Referencias](#inicio)

```{r refs, echo=FALSE, results="asis"}
PrintBibliography(myBib)
```

---
name: end-slide
class: end-slide, left, middle
count: false

# Gracias!! Preguntas??

```{r,echo=FALSE,child="assets/footer-presentation.Rmd"}
```

```{r,include=FALSE,eval=FALSE}
# manually run this to render this document to HTML
# rmarkdown::render("presentation.Rmd")
# manually run this to convert HTML to PDF
pagedown::chrome_print("presentation.html",output="presentation.pdf")
```
